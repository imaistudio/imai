import { NextRequest, NextResponse } from "next/server";
import Anthropic from "@anthropic-ai/sdk";
import { v2 as cloudinary } from "cloudinary";

cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET,
});

// Supported image formats for processing
const SUPPORTED_IMAGE_FORMATS = ['image/jpeg', 'image/jpg', 'image/png', 'image/webp'];
const SUPPORTED_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.webp'];

async function validateAndProcessImage(file: File): Promise<File> {
  console.log(`üîç Validating image: ${file.name} (${file.type}, ${file.size}b)`);
  
  // Check file size (max 10MB)
  const maxSize = 10 * 1024 * 1024; // 10MB
  if (file.size > maxSize) {
    throw new Error(`Image ${file.name} is too large (${Math.round(file.size / 1024 / 1024)}MB). Maximum size is 10MB.`);
  }

  // Check if it's a supported format
  const isValidMimeType = SUPPORTED_IMAGE_FORMATS.includes(file.type.toLowerCase());
  const hasValidExtension = SUPPORTED_EXTENSIONS.some(ext => 
    file.name.toLowerCase().endsWith(ext)
  );

  if (!isValidMimeType && !hasValidExtension) {
    throw new Error(`Unsupported image format: ${file.type || 'unknown'}. Supported formats: JPG, JPEG, PNG, WebP`);
  }

  // If it's already PNG, return as-is
  if (file.type === 'image/png' || file.name.toLowerCase().endsWith('.png')) {
    console.log(`‚úÖ Image ${file.name} is already PNG format`);
    return file;
  }

  // Convert to PNG for OpenAI compatibility
  console.log(`üîÑ Converting ${file.name} to PNG format...`);
  try {
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    
    // Create a new File object with PNG extension
    const pngFileName = file.name.replace(/\.[^/.]+$/, '') + '.png';
    const pngFile = new File([buffer], pngFileName, { type: 'image/png' });
    
    console.log(`‚úÖ Converted ${file.name} to ${pngFileName}`);
    return pngFile;
  } catch (error) {
    console.error(`‚ùå Failed to convert ${file.name} to PNG:`, error);
    throw new Error(`Failed to process image ${file.name}: ${error}`);
  }
}

async function processBase64Image(base64Data: string, filename: string = 'image.png'): Promise<File> {
  console.log(`üîç Processing base64 image: ${filename}`);
  
  try {
    // Remove data URL prefix if present
    const base64String = base64Data.replace(/^data:image\/[a-z]+;base64,/, '');
    
    // Convert base64 to buffer
    const buffer = Buffer.from(base64String, 'base64');
    
    // Create File object as PNG
    const pngFileName = filename.replace(/\.[^/.]+$/, '') + '.png';
    const file = new File([buffer], pngFileName, { type: 'image/png' });
    
    console.log(`‚úÖ Processed base64 image as ${pngFileName} (${file.size}b)`);
    return file;
  } catch (error) {
    console.error(`‚ùå Failed to process base64 image:`, error);
    throw new Error(`Failed to process base64 image: ${error}`);
  }
}

async function uploadImageToCloudinary(file: File): Promise<string> {
  try {
    console.log(`üì§ Uploading ${file.name} (${file.size}b) to Cloudinary...`);

    const bytes = await file.arrayBuffer();
    const buffer = Buffer.from(bytes);

    const result = await new Promise((resolve, reject) => {
      cloudinary.uploader
        .upload_stream(
          {
            resource_type: "image",
            folder: "intent_route_uploads",
            public_id: `${Date.now()}_${file.name.replace(/\.[^/.]+$/, "")}`,
            format: "png", // Always convert to PNG for consistency
            quality: "auto:best",
          },
          (error, result) => {
            if (error) reject(error);
            else resolve(result);
          }
        )
        .end(buffer);
    });

    const uploadResult = result as any;
    console.log(
      `‚úÖ Cloudinary upload successful (converted to PNG): ${uploadResult.secure_url}`
    );

    // Schedule deletion after 1 hour for testing
    setTimeout(async () => {
      try {
        await cloudinary.uploader.destroy(uploadResult.public_id);
        console.log(`üóëÔ∏è Deleted temporary image: ${uploadResult.public_id}`);
      } catch (error) {
        console.error("Error deleting temporary image:", error);
      }
    }, 3600000); // 1 hour

    return uploadResult.secure_url;
  } catch (error) {
    console.error("‚ùå Cloudinary upload failed:", error);
    throw new Error(`Failed to upload ${file.name} to Cloudinary: ${error}`);
  }
}

function formatFirebasePrivateKey(privateKey: string): string {
  if (!privateKey) {
    throw new Error("Firebase private key is empty or undefined");
  }

  let formattedKey = privateKey
    .replace(/^["']|["']$/g, "")
    .replace(/\\n/g, "\n")
    .replace(/\\\\/g, "\\")
    .trim();

  if (
    formattedKey === "-----BEGIN PRIVATE KEY-----" ||
    formattedKey.length < 100
  ) {
    console.log(
      "Skipping Firebase initialization due to environment variable issue - testing intent logic only"
    );
    return "SKIP_FIREBASE_INIT";
  }

  if (!formattedKey.includes("-----BEGIN")) {
    throw new Error(
      "Private key is missing PEM headers. Ensure it starts with -----BEGIN PRIVATE KEY-----"
    );
  }

  if (!formattedKey.includes("-----END")) {
    console.error(
      "Current private key content (first 100 chars):",
      formattedKey.substring(0, 100)
    );
    console.error(
      "Current private key content (last 100 chars):",
      formattedKey.substring(-100)
    );
    throw new Error(`Private key is missing PEM footers. Current key length: ${formattedKey.length}. Ensure it ends with -----END PRIVATE KEY-----. 
    
If you're having issues with multi-line environment variables, try setting FIREBASE_PRIVATE_KEY as a single line with \\n for line breaks, like:
FIREBASE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\\nYOUR_KEY_CONTENT\\n-----END PRIVATE KEY-----"`);
  }

  return formattedKey;
}

let firebaseInitialized = false;
console.log("üî• Firebase disabled - using Cloudinary for image handling");

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
  timestamp?: string;
}

interface IntentAnalysis {
  intent: string;
  confidence: number;
  endpoint: string;
  parameters: Record<string, any>;
  requiresFiles: boolean;
  explanation: string;
}

interface ChatResponse {
  status: "success" | "error";
  message: string;
  intent?: IntentAnalysis;
  result?: any;
  conversation_id?: string;
  error?: string;
}

async function parseClaudeIntent(response: any): Promise<IntentAnalysis> {
  const content = response.content[0];
  if (content.type !== "text") {
    throw new Error("Unexpected response type from Claude");
  }

  console.log("Claude response content:", content.text.substring(0, 200));
  let jsonStr = content.text.trim();
  
  // Enhanced JSON extraction logic
  const jsonExtractionSteps = [
    // Step 1: Try to find JSON in markdown code blocks
    (str: string) => {
      const jsonBlock = str.match(/```(?:json)?\s*(\{[\s\S]*?\})\s*```/);
      return jsonBlock ? jsonBlock[1].trim() : str;
    },
    // Step 2: Remove any leading/trailing non-JSON content
    (str: string) => {
      const jsonStart = str.indexOf('{');
      const jsonEnd = str.lastIndexOf('}') + 1;
      return jsonStart >= 0 && jsonEnd > jsonStart ? str.slice(jsonStart, jsonEnd) : str;
    },
    // Step 3: Clean up common formatting issues
    (str: string) => {
      return str
        .replace(/\n\s*\/\/.*$/gm, '') // Remove single-line comments
        .replace(/,\s*}/g, '}') // Remove trailing commas
        .replace(/,\s*]/g, ']') // Remove trailing commas in arrays
        .replace(/\s+/g, ' ') // Normalize whitespace
        .trim();
    }
  ];

  // Apply extraction steps in sequence
  jsonStr = jsonExtractionSteps.reduce((str, step) => step(str), jsonStr);

  // Validate JSON structure before parsing
  if (!jsonStr.startsWith('{') || !jsonStr.endsWith('}')) {
    throw new Error('Invalid JSON structure: missing opening/closing braces');
  }

  const intentAnalysis = JSON.parse(jsonStr);

  // Validate required fields with detailed error messages
  const requiredFields = [
    "intent",
    "confidence",
    "endpoint",
    "parameters",
    "requiresFiles",
    "explanation",
  ];

  const missingFields = requiredFields.filter(field => !(field in intentAnalysis));
  if (missingFields.length > 0) {
    throw new Error(`Missing required fields: ${missingFields.join(', ')}`);
  }

  // Validate field types and values
  if (typeof intentAnalysis.confidence !== 'number' || 
      intentAnalysis.confidence < 0 || 
      intentAnalysis.confidence > 1) {
    throw new Error('Invalid confidence value: must be a number between 0 and 1');
  }

  if (typeof intentAnalysis.requiresFiles !== 'boolean') {
    throw new Error('Invalid requiresFiles value: must be a boolean');
  }

  if (typeof intentAnalysis.parameters !== 'object' || intentAnalysis.parameters === null) {
    throw new Error('Invalid parameters: must be an object');
  }

  // Validate endpoint format
  if (intentAnalysis.endpoint !== 'none' && !intentAnalysis.endpoint.startsWith('/api/')) {
    throw new Error('Invalid endpoint format: must be "none" or start with "/api/"');
  }

  console.log("‚úÖ Parsed Claude intent analysis:", intentAnalysis);
  return intentAnalysis;
}

async function analyzeIntent(
  userMessage: string,
  conversationHistory: ChatMessage[] = [],
  formDataEntries: [string, FormDataEntryValue][] = [],
  lastGeneratedResult?: { imageUrl?: string; endpoint?: string; intent?: string }
): Promise<IntentAnalysis> {
  const smartFallbackAnalysis = (): IntentAnalysis => {
    const message = userMessage.toLowerCase();

    const hasProductImage =
      formDataEntries.some(([key]) => 
        key === "product_image" || 
        key === "product_image_url" || 
        key === "preset_product_type"
      ) ||
      conversationHistory.some(
        (msg) =>
          msg.content.includes("[Product Image:") ||
          msg.content.includes("product_image")
      );
    const hasDesignImage =
      formDataEntries.some(([key]) => 
        key === "design_image" || 
        key === "design_image_url" || 
        key === "preset_design_style"
      ) ||
      conversationHistory.some(
        (msg) =>
          msg.content.includes("[Design Image:") ||
          msg.content.includes("design_image")
      );
    const hasColorImage =
      formDataEntries.some(([key]) => 
        key === "color_image" || 
        key === "color_image_url" || 
        key === "preset_color_palette"
      ) ||
      conversationHistory.some(
        (msg) =>
          msg.content.includes("[Color Image:") ||
          msg.content.includes("color_image")
      );

    // Check for preset selections
    const hasPresetProduct = formDataEntries.some(([key]) => key === "preset_product_type");
    const hasPresetDesign = formDataEntries.some(([key]) => key === "preset_design_style");
    const hasPresetColor = formDataEntries.some(([key]) => key === "preset_color_palette");
    const hasAnyPresets = hasPresetProduct || hasPresetDesign || hasPresetColor;

    console.log("Smart fallback analysis - Image detection:", {
      hasProductImage,
      hasDesignImage,
      hasColorImage,
      hasPresetProduct,
      hasPresetDesign,
      hasPresetColor,
      hasAnyPresets,
      message: message.substring(0, 50),
    });

    const casualPatterns = [
      "hi",
      "hello",
      "hey",
      "howdy",
      "good morning",
      "good afternoon",
      "good evening",
      "how are you",
      "what's up",
      "whats up",
      "sup",
      "who are you",
      "what's your name",
      "whats your name",
      "tell me about yourself",
      "what can you do",
      "what do you do",
      "help me",
      "can you help",
      "i need help",
      "thank you",
      "thanks",
      "goodbye",
      "bye",
      "see you",
      "nice weather",
    ];

    // Check for design-related keywords that should NOT be casual conversation
    const designKeywords = [
      "shirt", "tshirt", "t-shirt", "design", "create", "make", "generate", 
      "product", "image", "picture", "photo", "art", "pattern", "color", 
      "style", "new", "custom", "hoodie", "pillow", "mug", "bag", "shoes",
      "dress", "jean", "plate", "notebook", "backpack", "lamp", "vase",
      "toys", "vehicle", "glasses", "watch", "earrings", "scarf", "blanket"
    ];

    const hasDesignKeywords = designKeywords.some(keyword => 
      message.toLowerCase().includes(keyword.toLowerCase())
    );

    const isCasualConversation = casualPatterns.some(
      (pattern) => message.includes(pattern) || message === pattern
    ) && !hasDesignKeywords; // Only casual if no design keywords present

    // üéØ PRIORITY: Direct routing for preset selections
    if (hasAnyPresets) {
      console.log("Smart fallback routing directly to design endpoint - preset selections detected");
      return {
        intent: "design",
        confidence: 0.95,
        endpoint: "/api/design",
        parameters: {
          workflow_type: "preset_design",
          size: "1024x1024",
          quality: "auto",
        },
        requiresFiles: false, // Presets don't require actual files
        explanation: "User selected preset options - routing directly to design endpoint",
      };
    }

    // üéØ PRIORITY: Check for specific image operations BEFORE general design routing
    if (hasProductImage || hasDesignImage || hasColorImage) {
      const imageCount = [hasProductImage, hasDesignImage, hasColorImage].filter(Boolean).length;

      // UPSCALE requests
      if (
        imageCount === 1 &&
        (message.includes("enhance") ||
          message.includes("upscale") ||
          message.includes("make bigger") ||
          message.includes("increase resolution") ||
          message.includes("improve quality"))
      ) {
        console.log("Smart fallback routing to upscale endpoint for single image enhancement");
        return {
          intent: "upscale_image",
          confidence: 0.95,
          endpoint: "/api/upscale",
          parameters: { quality: "auto" },
          requiresFiles: true,
          explanation: "User explicitly wants to enhance/upscale a single image",
        };
      }

      // REFRAME requests
      if (
        imageCount === 1 &&
        (message.includes("reframe") ||
          message.includes("crop") ||
          message.includes("landscape") ||
          message.includes("portrait") ||
          message.includes("square") ||
          message.includes("resize"))
      ) {
        console.log("Smart fallback routing to reframe endpoint for single image reframing");
        
        let imageSize = "square_hd"; // default
        if (message.includes("landscape")) {
          imageSize = "landscape";
        } else if (message.includes("portrait")) {
          imageSize = "portrait";
        } else if (message.includes("square")) {
          imageSize = "square_hd";
        }
        
        console.log(`üéØ Detected aspect ratio request: ${imageSize}`);
        
        return {
          intent: "reframe_image",
          confidence: 0.95,
          endpoint: "/api/reframe",
          parameters: { imageSize: imageSize },
          requiresFiles: true,
          explanation: `User explicitly wants to reframe/crop a single image to ${imageSize} format`,
        };
      }

      // ANALYZE requests
      if (
        imageCount === 1 &&
        (message.includes("analyze") ||
          message.includes("describe") ||
          message.includes("tell me about") ||
          message.includes("what is in") ||
          message.includes("what's in") ||
          message.includes("identify") ||
          message.includes("explain") ||
          message.includes("what do you see") ||
          message.includes("what can you see")) &&
        !message.includes("Create a design composition") &&
        !message.includes("design") &&
        !message.includes("create") &&
        !message.includes("make")
      ) {
        console.log("Smart fallback routing to analyze endpoint for single image analysis");
        return {
          intent: "analyze_image",
          confidence: 0.95,
          endpoint: "/api/analyzeimage",
          parameters: {},
          requiresFiles: true,
          explanation: "User explicitly wants to analyze a single specific image",
        };
      }
    }

    // üé® DESIGN REQUESTS: Route design-related requests to design endpoint
    if (hasDesignKeywords && !isCasualConversation) {
      console.log("Smart fallback routing to design endpoint - design keywords detected");
      return {
        intent: "design",
        confidence: 0.95, // Increased confidence to ensure smart fallback is used
        endpoint: "/api/design",
        parameters: {
          workflow_type: "prompt_only",
          size: "1024x1024",
          quality: "auto",
        },
        requiresFiles: false,
        explanation: "User request contains design-related keywords - routing to design endpoint",
      };
    }

    // Check for prompt enhancement requests
    if (
      message.includes("enhance my prompt") ||
      message.includes("improve this description") ||
      message.includes("make my prompt better") ||
      message.includes("expand this prompt") ||
      message.includes("enhance prompt")
    ) {
      console.log("Smart fallback routing to prompt enhancer");
      return {
        intent: "enhance_prompt",
        confidence: 0.9,
        endpoint: "/api/promptenhancer",
        parameters: { enhancement_type: "design" },
        requiresFiles: false,
        explanation: "User explicitly wants to enhance their prompt",
      };
    }

    // Check for title generation requests
    if (
      message.includes("create a title") ||
      message.includes("name this conversation") ||
      message.includes("generate title") ||
      message.includes("what should I call this") ||
      message.includes("title for this")
    ) {
      console.log("Smart fallback routing to title renamer");
      return {
        intent: "generate_title",
        confidence: 0.9,
        endpoint: "/api/titlerenamer",
        parameters: {},
        requiresFiles: false,
        explanation: "User explicitly wants to generate a title",
      };
    }

    if (
      isCasualConversation &&
      !hasProductImage &&
      !hasDesignImage &&
      !hasColorImage
    ) {
      console.log("Smart fallback detected casual conversation pattern");
      return {
        intent: "casual_conversation",
        confidence: 0.9,
        endpoint: "none",
        parameters: {
          conversation_type:
            message.includes("hi") || message.includes("hello")
              ? "greeting"
              : "general",
        },
        requiresFiles: false,
        explanation:
          "Detected casual conversation pattern - no image operation requested",
      };
    }

    if (hasProductImage || hasDesignImage || hasColorImage) {
      const imageCount = [
        hasProductImage,
        hasDesignImage,
        hasColorImage,
      ].filter(Boolean).length;

      if (
        message.includes("create a new design") ||
        message.includes("new design") ||
        (message.includes("create a design using") &&
          message.includes("these")) ||
        message.includes("make a new design") ||
        message.includes("design a new") ||
        message.includes("flow design") ||
        message.includes("create a flow design")
      ) {
        console.log(
          "Smart fallback routing to flowdesign endpoint for explicit new design creation"
        );
        return {
          intent: "create_design",
          confidence: 0.95,
          endpoint: "/api/flowdesign",
          parameters: {
            workflow_type: "multi_image_design",
            size: "1024x1024",
            quality: "auto",
          },
          requiresFiles: true,
          explanation:
            "User explicitly wants to create a NEW design using multiple images",
        };
      }

      if (
        (message.includes("apply") && message.includes("design")) ||
        message.includes("put this design on") ||
        message.includes("change my product design") ||
        message.includes("vintage but funky") ||
        message.includes("product composition")
      ) {
        console.log(
          "Smart fallback routing to design endpoint for product design application"
        );
        return {
          intent: "design",
          confidence: 0.95,
          endpoint: "/api/design",
          parameters: {
            workflow_type: "product_design",
            size: "1024x1024",
            quality: "auto",
          },
          requiresFiles: true,
          explanation:
            "User explicitly wants to apply a design to an existing product",
        };
      }

      // Clarity upscaler (keeping this one as it wasn't moved above)
      if (
        imageCount === 1 &&
        (message.includes("clarity") ||
          message.includes("clear up") ||
          message.includes("sharpen") ||
          message.includes("crisp") ||
          message.includes("detailed") ||
          message.includes("hd") ||
          message.includes("4k") ||
          message.includes("high definition"))
      ) {
        console.log(
          "Smart fallback routing to clarity upscaler for image clarity enhancement"
        );
        return {
          intent: "clarity_upscale",
          confidence: 0.9,
          endpoint: "/api/clarityupscaler",
          parameters: { upscaleFactor: 2, creativity: 0.35 },
          requiresFiles: true,
          explanation:
            "User explicitly wants to improve image clarity and detail",
        };
      }

      if (
        imageCount === 1 &&
        (message.includes("video") ||
          message.includes("animate") ||
          message.includes("motion") ||
          message.includes("move") ||
          message.includes("kling") ||
          message.includes("animation") ||
          message.includes("gif") ||
          message.includes("movie"))
      ) {
        console.log(
          "Smart fallback routing to kling endpoint for image-to-video"
        );
        return {
          intent: "create_video",
          confidence: 0.9,
          endpoint: "/api/kling",
          parameters: { duration: "5", cfg_scale: 0.5 },
          requiresFiles: true,
          explanation:
            "User explicitly wants to create video/animation from image",
        };
      }



      if (
        imageCount === 1 &&
        (message.includes("mirror") ||
          message.includes("symmetry") ||
          message.includes("reflection") ||
          message.includes("mirror effect"))
      ) {
        console.log(
          "Smart fallback routing to mirror magic endpoint for image mirroring"
        );
        return {
          intent: "mirror_magic",
          confidence: 0.9,
          endpoint: "/api/mirrormagic",
          parameters: { workflow: "mirror" },
          requiresFiles: true,
          explanation:
            "User explicitly wants to create mirror/symmetry effect on image",
        };
      }

      let workflowType = "prompt_only";
      if (hasProductImage && hasDesignImage && hasColorImage) {
        workflowType = "product_design_color";
      } else if (hasProductImage && hasDesignImage) {
        workflowType = "product_design";
      } else if (hasProductImage && hasColorImage) {
        workflowType = "product_color";
      } else if (hasDesignImage && hasColorImage) {
        workflowType = "design_color_prompt";
      } else if (hasProductImage) {
        workflowType = "product_prompt";
      } else if (hasDesignImage) {
        workflowType = "design_prompt";
      } else if (hasColorImage) {
        workflowType = "color_prompt";
      }

      console.log(
        `Smart fallback routing to design endpoint with workflow: ${workflowType}`
      );

      return {
        intent: "design",
        confidence: 0.9,
        endpoint: "/api/design",
        parameters: {
          prompt: userMessage,
          workflow_type: workflowType,
          size: "1024x1024",
          quality: "auto",
        },
        requiresFiles: true,
        explanation: `User uploaded ${imageCount} image(s) - defaulting to product composition with ${workflowType} workflow`,
      };
    }

    console.log(
      "Smart fallback defaulting to casual conversation - request unclear"
    );
    return {
      intent: "casual_conversation",
      confidence: 0.7,
      endpoint: "none",
      parameters: { conversation_type: "general" },
      requiresFiles: false,
      explanation:
        "Request unclear or ambiguous - defaulting to conversation for better user experience",
    };
  };

  // Reference detection patterns
  const referencePatterns = [
    "make it", "change it", "modify it", "update it", "alter it",
    "make this", "change this", "modify this", "update this",
    "make that", "change that", "modify that", "update that",
    "in [color]", "with [style]", "but [modification]",
    "add [element]", "remove [element]", "without [element]",
    "more [adjective]", "less [adjective]", "bigger", "smaller",
    "different color", "another color", "new color",
    "same but", "similar but", "like this but"
  ];

  const hasReference = referencePatterns.some(pattern => 
    userMessage.toLowerCase().includes(pattern.replace(/\[.*?\]/g, ''))
  );

  const systemPrompt = `You are IRIS, an AI intent recognition system for IMAI image platform with CONVERSATION CONTEXT AWARENESS.

CONTEXT ANALYSIS:
- You have access to conversation history and previous results
- Detect when users reference previous images/results with phrases like "make it", "change it", "modify this"
- If user references previous result, continue with the SAME operation type but with modifications

REFERENCE DETECTION:
${hasReference ? `üîç REFERENCE DETECTED: User is referring to a previous result with: "${userMessage}"` : ''}
${lastGeneratedResult ? `üìã LAST RESULT: ${lastGeneratedResult.intent} via ${lastGeneratedResult.endpoint}${lastGeneratedResult.imageUrl ? ` (Image: ${lastGeneratedResult.imageUrl})` : ''}` : ''}

CLASSIFICATION RULES:

1. CASUAL CONVERSATION ‚Üí endpoint: "none"
   - Greetings: "hi", "hello", "hey", "good morning"
   - Questions: "how are you?", "what can you do?", "help me"
   - Vague requests: "I need help", "what is this?"
   - ANY unclear/ambiguous requests WITHOUT context

2. REFERENCE-BASED OPERATIONS (when user refers to previous result):
   - "make it [color]" ‚Üí SAME endpoint as last result + color parameters
   - "change it to [style]" ‚Üí SAME endpoint as last result + style parameters
   - "make it bigger" ‚Üí /api/upscale (regardless of previous endpoint)
   - "crop it" ‚Üí /api/reframe (regardless of previous endpoint)
   - "analyze it" ‚Üí /api/analyzeimage (regardless of previous endpoint)

3. NEW IMAGE OPERATIONS ‚Üí specific API endpoint
   A. NEW PATTERN CREATION ‚Üí /api/flowdesign
      - ONLY for creating NEW abstract patterns/flows from scratch
      - "create a NEW pattern using these images"
      - "make a NEW pattern"
      - "new pattern with colors"
      - "flow pattern"
      - "create a flow pattern"
      - "generate abstract pattern"

   B. PRODUCT DESIGN ‚Üí /api/design
      - ONLY for applying designs TO products (t-shirts, mugs, etc.)
      - "make a design" 
      - "create a design" 
      - "apply design to product"
      - "put this design on the product"
      - "change my product design"
      - "design for t-shirt"
      - "product mockup"
      - ALSO for modifying existing designs with colors/styles
      - ALSO when user selects predefined product types, design styles, or color palettes from UI

   C. IMAGE ENHANCEMENT ‚Üí /api/upscale
      - "enhance this image"
      - "upscale this photo"
      - "make bigger"
      - "increase resolution"

   D. IMAGE CLARITY ‚Üí /api/clarityupscaler
      - "sharpen this image"
      - "improve clarity"
      - "make it crisp"
      - "high definition"

   E. IMAGE REFRAMING ‚Üí /api/reframe
      - "reframe my image"
      - "crop this picture"
      - "make it landscape/portrait"

   F. VIDEO CREATION ‚Üí /api/kling
      - "animate this image"
      - "create a video"
      - "make it move"

   G. IMAGE ANALYSIS ‚Üí /api/analyzeimage
      - "analyze this photo"
      - "what's in this image?"
      - "describe this image"

   H. MIRROR MAGIC ‚Üí /api/mirrormagic
      - "mirror this image"
      - "create symmetry"
      - "mirror effect"
      - "reflection"

   I. PROMPT ENHANCEMENT ‚Üí /api/promptenhancer
      - "enhance my prompt"
      - "improve this description"
      - "make my prompt better"
      - "expand this prompt"

   J. TITLE GENERATION ‚Üí /api/titlerenamer
      - "create a title"
      - "name this conversation"
      - "generate title"
      - "what should I call this"

CRITICAL RULES:
1. ALWAYS route to "none" for: greetings ONLY (without design requests), general questions about the platform, vague help requests
2. ALWAYS route explicit design/image generation requests to appropriate endpoints (even with greetings)
3. /api/flowdesign ‚Üí ONLY for creating NEW abstract patterns/flows from scratch
4. /api/design ‚Üí For generating images, creating designs, product compositions (t-shirts, mugs, etc.)
5. If request mentions "pattern" or "flow" ‚Üí /api/flowdesign
6. If request mentions "generate image", "create image", "make image", "design" ‚Üí /api/design
7. When in doubt about design vs conversation, choose design endpoint

CRITICAL CONTEXT RULES:
1. If user UPLOADED images + uses "it"/"this"/"that" ‚Üí They mean the UPLOADED image, NOT previous results
2. If user references previous result ("it", "this", "that") WITHOUT uploaded images ‚Üí Use SAME endpoint + modifications
3. If last result was design + user wants color change ‚Üí /api/design with color parameters
4. If last result was any type + user wants "bigger" ‚Üí /api/upscale
5. If last result was any type + user wants "crop" ‚Üí /api/reframe
6. Extract color/style parameters from reference requests
7. When in doubt with references, default to last used endpoint

UPLOADED IMAGE RULES:
1. If user uploaded image + wants "upscale"/"bigger"/"enhance" ‚Üí /api/upscale
2. If user uploaded image + wants "reframe"/"crop"/"landscape"/"portrait" ‚Üí /api/reframe
3. If user uploaded image + wants "analyze"/"describe"/"what is" ‚Üí /api/analyzeimage
4. If user uploaded image + wants "design"/"apply design" ‚Üí /api/design
5. If user uploaded image + wants "video"/"animate" ‚Üí /api/kling
6. If user uploaded image + wants "clarity"/"sharpen" ‚Üí /api/clarityupscaler

PREDEFINED SELECTION RULES:
1. If user selected product type, design style, or color palette WITHOUT specific instructions ‚Üí /api/design
2. If user selected predefined options + has text prompt ‚Üí Combine both for design generation
3. Predefined selections should be included in parameters for design endpoint

RESPONSE FORMAT:
{
  "intent": "casual_conversation|create_design|design|upscale_image|clarity_upscale|analyze_image|reframe_image|create_video|mirror_magic|enhance_prompt|generate_title",
  "confidence": 0.8-0.95,
  "endpoint": "none|/api/flowdesign|/api/design|/api/upscale|/api/clarityupscaler|/api/analyzeimage|/api/reframe|/api/kling|/api/mirrormagic|/api/promptenhancer|/api/titlerenamer",
  "parameters": {
    "workflow_type": "prompt_only|product_prompt|design_prompt|multi_image_design",
    "size": "1024x1024",
    "quality": "auto",
    "reference_image_url": "previous_result_url_if_referencing",
    "color_modification": "extracted_colors_if_mentioned",
    "style_modification": "extracted_style_if_mentioned"
  },
  "requiresFiles": true/false,
  "explanation": "Brief explanation including context awareness"
}`;

  // Try smart fallback first for speed optimization
  const smartResult = smartFallbackAnalysis();
  if (smartResult.confidence >= 0.9) {
    console.log("‚ö° Using smart fallback analysis (high confidence) - skipping Claude for speed");
    return smartResult;
  }

  try {
    console.log("üß† Analyzing intent with Claude Sonnet 4...");
    console.log("User message:", userMessage);
    console.log("API Key available:", !!process.env.ANTHROPIC_API_KEY);

    // Extract image metadata - check for any image-related fields
    const imageFileEntries = formDataEntries.filter(([key, value]) => {
      const isImageField = key.includes('image') || key === 'file' || key === 'product' || key === 'design' || key === 'color';
      const isValidFile = value instanceof File && value.size > 0;
      const isBase64 = typeof value === 'string' && value.startsWith('data:image/');
      return isImageField && (isValidFile || isBase64);
    });

    const hasUploadedImages = imageFileEntries.length > 0;

    // Extract predefined selections from constants
    const productType = formDataEntries.find(([key]) => key === 'product_type')?.[1] as string || "";
    const designStyles = formDataEntries.filter(([key]) => key.startsWith('design_style_')).map(([key, value]) => value as string);
    const colorPalettes = formDataEntries.filter(([key]) => key.startsWith('color_palette_')).map(([key, value]) => value as string);

    // Build conversation context
    const recentHistory = conversationHistory.slice(-4); // Last 4 messages for context
    const contextSummary = recentHistory.length > 0 
      ? recentHistory.map(msg => `${msg.role}: ${msg.content.slice(0, 100)}${msg.content.length > 100 ? '...' : ''}`).join('\n')
      : "No previous conversation";

    // Build a clear, structured prompt with context
    const prompt = `
Analyze this user message with full conversation context:

CURRENT USER MESSAGE: "${userMessage}"

UPLOADED IMAGES IN THIS REQUEST: ${hasUploadedImages ? `YES (${imageFileEntries.length} images uploaded)` : 'NO'}
${hasUploadedImages ? imageFileEntries.map(([key]) => `- ${key}`).join("\n") : ''}

PREDEFINED SELECTIONS FROM UI:
- Product Type: ${productType || "None selected"}
- Design Styles: ${designStyles.length > 0 ? designStyles.join(", ") : "None selected"}
- Color Palettes: ${colorPalettes.length > 0 ? colorPalettes.join(", ") : "None selected"}

RECENT CONVERSATION HISTORY:
${contextSummary}

${lastGeneratedResult ? `
PREVIOUS RESULT CONTEXT:
- Last operation: ${lastGeneratedResult.intent} 
- Last endpoint: ${lastGeneratedResult.endpoint}
- Generated image: ${lastGeneratedResult.imageUrl || 'None'}
` : ''}

REFERENCE ANALYSIS:
- Contains reference words: ${hasReference ? 'YES' : 'NO'}
- Has uploaded images: ${hasUploadedImages ? 'YES' : 'NO'}
- Likely referring to UPLOADED image: ${hasReference && hasUploadedImages ? 'YES' : 'NO'}
- Likely referring to PREVIOUS result: ${hasReference && lastGeneratedResult && !hasUploadedImages ? 'YES' : 'NO'}

CRITICAL: If user uploaded images and uses words like "it", "this", "that" - they are referring to the UPLOADED images, NOT previous results!

Follow system instructions and return intent JSON only.`;

    let intentAnalysis;
    try {
      const response = await anthropic.messages.create({
        model: "claude-sonnet-4-20250514",
        max_tokens: 1024,
        temperature: 0.1,
        system: systemPrompt,
        messages: [
          {
            role: "user",
            content: prompt,
          },
        ],
      });

      intentAnalysis = await parseClaudeIntent(response);
    } catch (error) {
      console.warn("‚ö†Ô∏è First attempt failed, retrying Claude intent parsing...");
      
      // Retry with slightly higher temperature for more creative parsing
      const retryResponse = await anthropic.messages.create({
        model: "claude-sonnet-4-20250514",
        max_tokens: 1024,
        temperature: 0.2, // Slightly higher temperature for retry
        system: systemPrompt,
        messages: [
          {
            role: "user",
            content: prompt + "\n\nPlease ensure your response is valid JSON.",
          },
        ],
      });

      intentAnalysis = await parseClaudeIntent(retryResponse);
    }

    return intentAnalysis;
  } catch (error: any) {
    console.error("‚ùå Error in intent analysis:", error);
    console.log("üîÑ Using smart fallback analysis");
    return smartFallbackAnalysis();
  }
}

async function generateResponse(
  userMessage: string,
  intentAnalysis: IntentAnalysis,
  apiResult?: any
): Promise<string> {
  const smartFallbackResponse = (): string => {
    if (apiResult) {
      if (apiResult.status === "success") {
        const hasOutput =
          apiResult.firebaseOutputUrl ||
          apiResult.data_url ||
          apiResult.outputUrl ||
          apiResult.output_image ||
          apiResult.imageUrl;
        return `üéâ Fantastic! I've successfully processed your ${intentAnalysis.intent.replace("_", " ")} request${hasOutput ? " and your result is ready for download!" : "!"} Feel free to try more IMAI features!`;
      } else {
        return `‚ö†Ô∏è I encountered an issue while processing your request: ${apiResult.error || "Unknown error"}. Let's try again - I'm here to help you create amazing images! üé®`;
      }
    } else {
      if (intentAnalysis.requiresFiles) {
        return `üìÅ I understand you want to ${intentAnalysis.intent.replace("_", " ")}! Please upload the required files and I'll process them for you using IMAI's powerful tools.`;
      } else if (
        intentAnalysis.endpoint === "none" ||
        intentAnalysis.intent === "casual_conversation"
      ) {
        return `üëã Hi there! I'm IRIS, your AI assistant for IMAI - an advanced image generation platform! I can help you create stunning product designs, upscale images, analyze visuals, and so much more. What would you like to create today? üé®`;
      } else {
        return `‚ú® I can help you with ${intentAnalysis.intent.replace("_", " ")}! Let me process that for you using IMAI's capabilities.`;
      }
    }
  };

  try {
    // Use smart response for casual conversations to avoid Claude API call
    if (intentAnalysis.intent === "casual_conversation" && intentAnalysis.confidence >= 0.9) {
      console.log("‚ö° Using smart response generation - skipping Claude for speed");
      return smartFallbackResponse();
    }

    console.log("üó£Ô∏è Generating conversational response with Claude...");

    let prompt = "";

    if (apiResult) {
      if (apiResult.status === "success") {
        const hasOutput =
          apiResult.firebaseOutputUrl ||
          apiResult.data_url ||
          apiResult.outputUrl ||
          apiResult.output_image ||
          apiResult.imageUrl;
        // Special handling for image analysis - include the actual analysis content
        if (intentAnalysis.intent === "analyze_image" && apiResult.result) {
          const analysisContent = apiResult.result.raw_analysis || JSON.stringify(apiResult.result, null, 2);
          prompt = `The user said: "${userMessage}"

I successfully analyzed their image using ${intentAnalysis.endpoint}. Here's what I found:

${analysisContent}

Generate a friendly, conversational response that INCLUDES the key findings from this analysis. Summarize the main visual elements (colors, shapes, textures, composition) in natural language. Be specific about what you see. Keep it engaging but informative (3-4 sentences max). Use 1-2 emojis.`;
        } else {
          const resultSummary = {
            status: apiResult.status,
            hasOutput: !!hasOutput,
            endpoint: intentAnalysis.endpoint,
            intent: intentAnalysis.intent,
          };

          prompt = `The user said: "${userMessage}"

I successfully processed their request using ${intentAnalysis.endpoint}. The intent was: ${intentAnalysis.intent}

API Response Summary: ${JSON.stringify(resultSummary, null, 2)}

Generate a friendly, conversational response (2-3 sentences max) explaining what was accomplished. ${hasOutput ? "Mention that their result is ready." : ""} Be encouraging and helpful. Use emojis sparingly.`;
        }
      } else {
        prompt = `The user said: "${userMessage}"

I tried to process their request using ${intentAnalysis.endpoint} but encountered an error.

Error: ${apiResult.error || "Unknown error"}

Generate a helpful response (2-3 sentences max) explaining what went wrong and suggest how they might try again. Be supportive and offer alternatives if possible.`;
      }
    } else {
      if (intentAnalysis.requiresFiles) {
        prompt = `The user said: "${userMessage}"

I understand they want to: ${intentAnalysis.intent}
This requires using ${intentAnalysis.endpoint}

Generate a helpful response (2-3 sentences max) explaining what files they need to upload and how to proceed. Be encouraging and clear about next steps.`;
      } else {
        prompt = `The user said: "${userMessage}"

This seems like general conversation about our image AI platform capabilities.

Generate a friendly, helpful response (2-3 sentences max). Briefly explain what kinds of image generation and manipulation tasks I can help with. Be welcoming and encourage them to try something.`;
      }
    }

    // Call Claude for response generation (same pattern as old working code)
    const response = await anthropic.messages.create({
      model: "claude-sonnet-4-20250514", // Same model as working old code
      max_tokens: 400, // Slightly longer for better introductions
      temperature: 0.7,
      system: `You are IRIS, the AI assistant for IMAI - an advanced image generation and manipulation platform. 

**Your personality:**
- Friendly, helpful, and conversational
- Always introduce yourself as IRIS when greeting new users
- Enthusiastic about image creation and design
- Concise but informative (2-4 sentences max)

**IMAI Platform Capabilities:**
- üé® Product design composition (combine product, design, and color references)
- ‚¨ÜÔ∏è Image upscaling and enhancement  
- üîç Image analysis and description
- üñºÔ∏è Image reframing and cropping
- ‚ú® Prompt enhancement for better results
- üéØ Elemental and flow-based design creation

**Response Guidelines:**
- For greetings: Introduce yourself as IRIS, welcome them to IMAI, briefly mention 2-3 key capabilities
- For conversations: Be friendly and guide them toward trying image features
- For successful results: Celebrate their success and encourage them to try more
- For errors: Be supportive and offer helpful alternatives
- Use 1-2 emojis max, keep it natural and professional`,
      messages: [
        {
          role: "user",
          content: prompt,
        },
      ],
    });

    console.log("‚úÖ Claude response generation successful");

    const content = response.content[0];
    return content.type === "text"
      ? content.text.trim()
      : "I apologize, but I had trouble generating a response.";
  } catch (error: any) {
    console.error("‚ùå Error generating Claude response:", error);
    console.log("üîÑ Using smart fallback response generation");
    return smartFallbackResponse();
  }
}

async function routeToAPI(
  endpoint: string,
  parameters: Record<string, any>,
  files: FormData,
  userid: string,
  originalMessage: string,
  imageUrls: Record<string, string> = {}
): Promise<any> {
  try {
    const baseUrl = process.env.VERCEL_URL
      ? `https://${process.env.VERCEL_URL}`
      : "http://localhost:3000";

    // Create FormData for the API call
    const formData = new FormData();
    formData.append("userid", userid);
    console.log("üîó Using URL-based API routing with imageUrls:", imageUrls);

    // Helper function to extract category from preset path
    const extractPresetCategory = (path: string): string => {
      if (path.includes('/')) {
        // Extract filename without extension
        return path.split('/').pop()?.split('.')[0] || path;
      }
      return path;
    };

    // Extract preset selections from the original FormData
    const presetSelections: Record<string, string | string[]> = {};
    const fileEntries = Array.from(files.entries());
    for (const [key, value] of fileEntries) {
      if (key.startsWith('preset_') && typeof value === 'string') {
        let processedValue = value;
        
        // Extract category from path for design and color presets
        if (key === 'preset_design_style' || key === 'preset_color_palette') {
          processedValue = extractPresetCategory(value);
        }
        
        // Handle multiple selections for the same key
        if (presetSelections[key]) {
          // Convert to array if not already
          if (Array.isArray(presetSelections[key])) {
            (presetSelections[key] as string[]).push(processedValue);
          } else {
            presetSelections[key] = [presetSelections[key] as string, processedValue];
          }
        } else {
          presetSelections[key] = processedValue;
        }
        console.log(`üìã Found preset selection: ${key} = ${processedValue} (from ${value})`);
      }
    }

    if (endpoint === "/api/design" || endpoint === "/api/design") {
      formData.append("prompt", originalMessage);

      // Add design-specific parameters
      if (parameters.workflow_type) {
        formData.append("workflow_type", parameters.workflow_type);
      }
      if (parameters.size) {
        formData.append("size", parameters.size);
      }
      if (parameters.quality) {
        formData.append("quality", parameters.quality);
      }

      // Add color/style modifications if specified
      if (parameters.color_modification) {
        formData.append("color_modification", parameters.color_modification);
        console.log("üé® Added color modification:", parameters.color_modification);
      }
      if (parameters.style_modification) {
        formData.append("style_modification", parameters.style_modification);
        console.log("‚ú® Added style modification:", parameters.style_modification);
      }

      // üéØ Pass image URLs instead of files - check all possible key patterns
      const imageFields = ['product_image', 'design_image', 'color_image'];
      imageFields.forEach(field => {
        if (imageUrls[field]) {
          formData.append(`${field}_url`, imageUrls[field]);
          console.log(`üîó Added ${field}_url:`, imageUrls[field]);
        }
      });

      // Also check for any processed URLs from file uploads that might have different key names
      Object.keys(imageUrls).forEach(key => {
        if (key.includes('product') && !formData.has('product_image_url')) {
          formData.append('product_image_url', imageUrls[key]);
          console.log(`üîó Added product_image_url from ${key}:`, imageUrls[key]);
        } else if (key.includes('design') && !formData.has('design_image_url')) {
          formData.append('design_image_url', imageUrls[key]);
          console.log(`üîó Added design_image_url from ${key}:`, imageUrls[key]);
        } else if (key.includes('color') && !formData.has('color_image_url')) {
          formData.append('color_image_url', imageUrls[key]);
          console.log(`üîó Added color_image_url from ${key}:`, imageUrls[key]);
        }
      });

      // üîÑ Add reference image if this is a modification request
      if (parameters.reference_image_url && !formData.has('product_image_url') && !formData.has('design_image_url')) {
        formData.append("product_image_url", parameters.reference_image_url);
        console.log("üîÑ Added reference image as product_image_url:", parameters.reference_image_url);
      }

      // üìã Handle preset selections
      if (presetSelections.preset_product_type) {
        const productType = Array.isArray(presetSelections.preset_product_type) 
          ? presetSelections.preset_product_type.join(', ') 
          : presetSelections.preset_product_type;
        formData.append("preset_product_type", productType);
        console.log("üìã Added preset product type:", productType);
      }
      if (presetSelections.preset_design_style) {
        const designStyle = Array.isArray(presetSelections.preset_design_style) 
          ? presetSelections.preset_design_style.join(', ') 
          : presetSelections.preset_design_style;
        formData.append("preset_design_style", designStyle);
        console.log("üìã Added preset design style:", designStyle);
      }
      if (presetSelections.preset_color_palette) {
        const colorPalette = Array.isArray(presetSelections.preset_color_palette) 
          ? presetSelections.preset_color_palette.join(', ') 
          : presetSelections.preset_color_palette;
        formData.append("preset_color_palette", colorPalette);
        console.log("üìã Added preset color palette:", colorPalette);
      }
    } else if (endpoint === "/api/flowdesign") {
      formData.append("prompt", originalMessage);

      if (parameters.workflow_type) {
        formData.append("workflow_type", parameters.workflow_type);
      }
      if (parameters.size) {
        formData.append("size", parameters.size);
      }
      if (parameters.quality) {
        formData.append("quality", parameters.quality);
      }

      if (imageUrls.product_image) {
        formData.append("product_image_url", imageUrls.product_image);
        console.log(
          "üîó Added product_image_url for flow design:",
          imageUrls.product_image
        );
      }
      if (imageUrls.design_image) {
        formData.append("design_image_url", imageUrls.design_image);
        console.log(
          "üîó Added design_image_url for flow design:",
          imageUrls.design_image
        );
      }
      if (imageUrls.color_image) {
        formData.append("color_image_url", imageUrls.color_image);
        console.log(
          "üîó Added color_image_url for flow design:",
          imageUrls.color_image
        );
      }
    } else if (endpoint === "/api/analyzeimage") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.product_image_image ||
        imageUrls.design_image ||
        imageUrls.design_image_image ||
        imageUrls.color_image ||
        imageUrls.color_image_image;

      if (imageUrl) {
        formData.append("image_url", imageUrl);
        console.log("üîó Added image_url for analysis:", imageUrl);
      } else {
        console.log("üîç Available imageUrls keys:", Object.keys(imageUrls));
        throw new Error("No image URL found for analysis");
      }

      Object.entries(parameters).forEach(([key, value]) => {
        if (value !== undefined && value !== null && key !== "image_url") {
          formData.append(key, String(value));
        }
      });
    } else if (endpoint === "/api/upscale") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.product_image_image ||
        imageUrls.design_image ||
        imageUrls.design_image_image ||
        imageUrls.color_image ||
        imageUrls.color_image_image;

      if (imageUrl) {
        formData.append("image_url", imageUrl);
        console.log("üîó Added image_url for upscaling:", imageUrl);
      } else {
        console.log("üîç Available imageUrls keys:", Object.keys(imageUrls));
        throw new Error("No image URL found for upscaling");
      }

      // Add other upscale-specific parameters
      Object.entries(parameters).forEach(([key, value]) => {
        if (value !== undefined && value !== null) {
          formData.append(key, String(value));
        }
      });

      if (originalMessage && !parameters.prompt) {
        formData.append("prompt", originalMessage);
      }
    } else if (endpoint === "/api/reframe") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.product_image_image ||
        imageUrls.design_image ||
        imageUrls.design_image_image ||
        imageUrls.color_image ||
        imageUrls.color_image_image;

      if (imageUrl) {
        formData.append("image_url", imageUrl);
        console.log("üîó Added image_url for reframing:", imageUrl);
      } else {
        console.log("üîç Available imageUrls keys:", Object.keys(imageUrls));
        throw new Error("No image URL found for reframing");
      }

      Object.entries(parameters).forEach(([key, value]) => {
        if (value !== undefined && value !== null) {
          formData.append(key, String(value));
        }
      });

      if (originalMessage && !parameters.prompt) {
        formData.append("prompt", originalMessage);
      }
    } else if (endpoint === "/api/clarityupscaler") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.design_image ||
        imageUrls.color_image;

      if (imageUrl) {
        const clarityPayload = {
          imageUrl: imageUrl,
          prompt:
            parameters.prompt ||
            originalMessage ||
            "masterpiece, best quality, highres",
          upscaleFactor: parameters.upscaleFactor || 2,
          creativity: parameters.creativity || 0.35,
          resemblance: parameters.resemblance || 0.6,
          guidanceScale: parameters.guidanceScale || 4,
          numInferenceSteps: parameters.numInferenceSteps || 18,
          enableSafetyChecker: true,
        };

        console.log("üîó Added clarity upscaler payload:", clarityPayload);

        const response = await fetch(`${baseUrl}${endpoint}`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(clarityPayload),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`API call failed: ${response.status} ${errorText}`);
        }

        return await response.json();
      } else {
        throw new Error("No image URL found for clarity upscaling");
      }
    } else if (endpoint === "/api/kling") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.design_image ||
        imageUrls.color_image;

      if (imageUrl) {
        formData.append("image_url", imageUrl);
        formData.append(
          "prompt",
          parameters.prompt ||
            originalMessage ||
            "Create a smooth transition video"
        );
        console.log("üîó Added image_url for kling video creation:", imageUrl);
      } else {
        throw new Error("No image URL found for video creation");
      }

      // Add other kling-specific parameters
      Object.entries(parameters).forEach(([key, value]) => {
        if (value !== undefined && value !== null && key !== "image_url") {
          formData.append(key, String(value));
        }
      });
    } else if (endpoint === "/api/mirrormagic") {
      const imageUrl =
        imageUrls.product_image ||
        imageUrls.design_image ||
        imageUrls.color_image;

      if (imageUrl) {
        formData.append("image_url", imageUrl);
        console.log("üîó Added image_url for mirror magic:", imageUrl);
      } else {
        throw new Error("No image URL found for mirror magic transformation");
      }

      // Add mirror magic specific parameters
      if (parameters.workflow) {
        formData.append("workflow", parameters.workflow);
      }
      if (parameters.size) {
        formData.append("size", parameters.size);
      }
      if (parameters.quality) {
        formData.append("quality", parameters.quality);
      }
      if (parameters.n) {
        formData.append("n", String(parameters.n));
      }

      // Add prompt if provided
      if (originalMessage && !parameters.prompt) {
        formData.append("prompt", originalMessage);
      } else if (parameters.prompt) {
        formData.append("prompt", parameters.prompt);
      }
    } else if (endpoint === "/api/promptenhancer") {
      // Add prompt enhancer parameters
      formData.append("prompt", originalMessage);
      
      if (parameters.enhancement_type) {
        formData.append("enhancement_type", parameters.enhancement_type);
      }
      
      // Add image context flags
      if (imageUrls.product_image) {
        formData.append("has_product_image", "true");
      }
      if (imageUrls.design_image) {
        formData.append("has_design_image", "true");
      }
      if (imageUrls.color_image) {
        formData.append("has_color_image", "true");
      }
      
      console.log("üîó Added prompt enhancer parameters for:", originalMessage);
    } else if (endpoint === "/api/titlerenamer") {
      // Add title renamer parameters
      if (parameters.messages) {
        formData.append("messages", JSON.stringify(parameters.messages));
      } else {
        // Create a basic message structure if not provided
        const messages = [
          { role: "user", content: originalMessage, timestamp: new Date().toISOString() }
        ];
        formData.append("messages", JSON.stringify(messages));
      }
      
      console.log("üîó Added title renamer parameters");
    } else {
      Object.entries(parameters).forEach(([key, value]) => {
        if (value !== undefined && value !== null) {
          formData.append(key, String(value));
        }
      });

      if (originalMessage && !parameters.prompt) {
        formData.append("prompt", originalMessage);
      }
    }

    console.log(`üöÄ Calling ${endpoint} with URL-based parameters:`, {
      prompt: originalMessage,
      otherParams: Object.keys(parameters),
      imageUrls: Object.keys(imageUrls),
      hasFiles: false,
    });

    const response = await fetch(`${baseUrl}${endpoint}`, {
      method: "POST",
      body: formData,
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`API call failed: ${response.status} ${errorText}`);
    }

    return await response.json();
  } catch (error) {
    console.error(`Error calling ${endpoint}:`, error);
    throw error;
  }
}

export async function POST(request: NextRequest): Promise<NextResponse> {
  try {
    const formData = await request.formData();
    console.log("=== Intent Route Debug ===");
    console.log("FormData entries:");
    const entries = Array.from(formData.entries());
    entries.forEach(([key, value]) => {
      console.log(
        `  ${key}:`,
        typeof value === "string" ? value : `[File: ${value}]`
      );
    });

    // 1) Extract and validate userid
    let userid = (formData.get("userid") as string | null)?.trim();
    console.log("Extracted userid:", userid);
    if (!userid) {
      console.log(
        "‚ùå Missing userid parameter - using valid user for debugging"
      );
      userid = "uTiXKRbCYbhWnBbkLFZoMdEMdgf2";
      formData.set("userid", userid);
      console.log("‚úÖ Using fallback userid:", userid);
    } else {
      console.log("‚úÖ Got userid:", userid);
    }
    if (firebaseInitialized) {
      try {
        // await getAuth().getUser(userid);
      } catch {
        console.log("‚ùå Invalid Firebase user ID");
        return NextResponse.json(
          { status: "error", error: "Invalid Firebase user ID" },
          { status: 400 }
        );
      }
    } else {
      console.log("Skipping Firebase user validation - testing mode");
    }

    const message = (formData.get("message") as string)?.trim();
    console.log("Extracted message:", message);

    // Check for all types of image inputs
    const hasActualImages = entries.some(
      ([key, value]) => {
        // Check for standard image fields (files)
        const isStandardImageField = ["product_image", "design_image", "color_image", "image", "file"].includes(key);
        const isValidFile = value instanceof File && value.size > 0;
        
        // Check for base64 data fields
        const isBase64Field = key.endsWith('_base64');
        const isBase64Data = typeof value === 'string' && value.startsWith('data:image/');
        
        // Check for URL fields
        const isUrlField = key.endsWith('_url');
        const isValidUrl = typeof value === 'string' && (value.startsWith('http') || value.startsWith('/'));
        
        // Legacy base64 detection
        const isLegacyBase64 = typeof value === 'string' && 
          (value.startsWith('data:image/') || value.match(/^[A-Za-z0-9+/]+=*$/));
        
        return (isStandardImageField && isValidFile) || 
               (isBase64Field && isBase64Data) || 
               (isUrlField && isValidUrl) ||
               (key.startsWith('image') && isLegacyBase64);
      }
    );

    const hasPresetSelections = entries.some(
      ([key, value]) => {
        return key.startsWith('preset_') && typeof value === 'string' && value.trim().length > 0;
      }
    );

    const hasImages = hasActualImages || hasPresetSelections;
    console.log("Has actual images:", hasActualImages);
    console.log("Has preset selections:", hasPresetSelections);
    console.log("Has images (combined):", hasImages);

    if (!message && !hasImages) {
      console.log("‚ùå Missing both message and images");
      return NextResponse.json(
        {
          status: "error",
          error: "Either a message or images must be provided",
        },
        { status: 400 }
      );
    }

    const effectiveMessage =
      message || "Create a design composition using the uploaded images";
    console.log("Effective message:", effectiveMessage);

    const conversationHistoryStr = formData.get(
      "conversation_history"
    ) as string;
    let conversationHistory: ChatMessage[] = [];
    if (conversationHistoryStr) {
      try {
        conversationHistory = JSON.parse(conversationHistoryStr);
      } catch {
        conversationHistory = [];
      }
    }

    console.log("‚úÖ Validation passed, proceeding with intent analysis");

    const imageUrls: Record<string, string> = {};
    
    // Process all types of image inputs
    const allImageEntries = entries.filter(([key, value]) => {
      // Files
      const isFileField = ["product_image", "design_image", "color_image", "image", "file"].includes(key) ||
                         key.startsWith('image');
      const isValidFile = value instanceof File && value.size > 0;
      
      // Base64 data
      const isBase64Field = key.endsWith('_base64');
      const isBase64Data = typeof value === 'string' && value.startsWith('data:image/');
      
      // URLs
      const isUrlField = key.endsWith('_url');
      const isValidUrl = typeof value === 'string' && (value.startsWith('http') || value.startsWith('/'));
      
      // Preset selections
      const isPresetField = key.startsWith('preset_');
      const isValidPreset = typeof value === 'string' && value.trim().length > 0;
      
      return (isFileField && isValidFile) || 
             (isBase64Field && isBase64Data) || 
             (isUrlField && isValidUrl) ||
             (isPresetField && isValidPreset);
    });

    if (allImageEntries.length > 0) {
      console.log("üå§Ô∏è Processing", allImageEntries.length, "image inputs...");

      try {
        const processPromises = allImageEntries.map(async ([key, value]) => {
          // Handle preset selections
          if (key.startsWith('preset_')) {
            console.log(`üìã Processing preset: ${key} = ${value}`);
            return { key, value: value as string, type: 'preset' };
          }
          
          // Handle URL inputs
          if (key.endsWith('_url')) {
            const url = value as string;
            console.log(`üîó Processing URL: ${key} = ${url}`);
            
            if (url.startsWith('/')) {
              // Local path - convert to full URL
              const fullUrl = `${process.env.VERCEL_URL ? `https://${process.env.VERCEL_URL}` : 'http://localhost:3000'}${url}`;
              console.log(`üîÑ Converting local path to full URL: ${fullUrl}`);
              
              try {
                const response = await fetch(fullUrl);
                const blob = await response.blob();
                const file = new File([blob], `${key.replace('_url', '')}.png`, { type: 'image/png' });
                const processedFile = await validateAndProcessImage(file);
                const imageUrl = await uploadImageToCloudinary(processedFile);
                
                // Convert URL field to standard image field
                const standardKey = key.replace('_url', '_image');
                return { key: standardKey, value: imageUrl, type: 'url' };
              } catch (error) {
                console.warn(`‚ö†Ô∏è Failed to fetch local URL ${fullUrl}:`, error);
                return null;
              }
            } else {
              // External URL - fetch and process
              try {
                const response = await fetch(url);
                const blob = await response.blob();
                const file = new File([blob], `${key.replace('_url', '')}.png`, { type: 'image/png' });
                const processedFile = await validateAndProcessImage(file);
                const imageUrl = await uploadImageToCloudinary(processedFile);
                
                // Convert URL field to standard image field
                const standardKey = key.replace('_url', '_image');
                return { key: standardKey, value: imageUrl, type: 'url' };
              } catch (error) {
                console.warn(`‚ö†Ô∏è Failed to fetch external URL ${url}:`, error);
                return null;
              }
            }
          }
          
          // Handle base64 inputs
          if (key.endsWith('_base64')) {
            console.log(`üìÑ Processing base64: ${key}`);
            const base64Data = value as string;
            const processedFile = await processBase64Image(base64Data, `${key.replace('_base64', '')}.png`);
            const imageUrl = await uploadImageToCloudinary(processedFile);
            
            // Convert base64 field to standard image field
            const standardKey = key.replace('_base64', '_image');
            return { key: standardKey, value: imageUrl, type: 'base64' };
          }
          
          // Handle file uploads
          if (value instanceof File) {
            console.log(`üìÅ Processing file: ${key}`);
            const processedFile = await validateAndProcessImage(value);
            const imageUrl = await uploadImageToCloudinary(processedFile);
            return { key, value: imageUrl, type: 'file' };
          }
          
          return null;
        });

        const processResults = await Promise.all(processPromises);
        
        // Separate processed images and presets
        const processedImages = processResults.filter(result => result && result.type !== 'preset');
        const presetSelections = processResults.filter(result => result && result.type === 'preset');
        
        // Store image URLs
        processedImages.forEach(result => {
          if (result) {
            imageUrls[result.key] = result.value;
            console.log(`üîó ${result.key} ‚Üí ${result.value}`);
          }
        });
        
        // Process preset selections
        presetSelections.forEach(result => {
          if (result) {
            console.log(`üìã Preset processed: ${result.key} = ${result.value}`);
            // Add preset selections back to formData for downstream processing
            formData.set(result.key, result.value);
          }
        });

        console.log("‚úÖ All image processing successful!");
        console.log("üìã Image URLs:", imageUrls);
        console.log("üìã Preset selections:", presetSelections.length);
      } catch (error) {
        console.error("‚ùå Image processing failed:", error);
        return NextResponse.json(
          { status: "error", error: `Image processing failed: ${error}` },
          { status: 500 }
        );
      }
    } else {
      console.log("üì∑ No images to process");
    }

    // Extract last generated result from conversation history for context
    let lastGeneratedResult: { imageUrl?: string; endpoint?: string; intent?: string } | undefined;
    if (conversationHistory.length > 0) {
      // Look for the most recent assistant message with result information
      for (let i = conversationHistory.length - 1; i >= 0; i--) {
        const msg = conversationHistory[i];
        if (msg.role === "assistant") {
          try {
            // Try to extract result info from assistant message - look for various patterns
            const firebaseUrlMatch = msg.content.match(/firebaseOutputUrl['":\s]*([^"'\s,}]+)/);
            const imageUrlMatch = msg.content.match(/imageUrl['":\s]*([^"'\s,}]+)/);
            const outputUrlMatch = msg.content.match(/outputUrl['":\s]*([^"'\s,}]+)/);
            const dataUrlMatch = msg.content.match(/data_url['":\s]*([^"'\s,}]+)/);
            
            // Look for endpoint and intent information
            const endpointMatch = msg.content.match(/endpoint['":\s]*([^"'\s,}]+)/) || 
                                 msg.content.match(/‚Üí\s*([\/\w]+)/); // Match "‚Üí /api/design" pattern
            const intentMatch = msg.content.match(/intent['":\s]*([^"'\s,}]+)/) ||
                               msg.content.match(/Intent:\s*(\w+)/); // Match "Intent: design" pattern
            
            // Extract image URL from any of the possible fields
            const extractedImageUrl = firebaseUrlMatch?.[1] || imageUrlMatch?.[1] || 
                                     outputUrlMatch?.[1] || dataUrlMatch?.[1];
            
            if (extractedImageUrl || endpointMatch || intentMatch) {
              lastGeneratedResult = {
                imageUrl: extractedImageUrl,
                endpoint: endpointMatch?.[1],
                intent: intentMatch?.[1]
              };
              console.log("üîç Extracted last result context:", lastGeneratedResult);
              break;
            }
          } catch (error) {
            console.log("‚ö†Ô∏è Could not parse last result context from message:", msg.content.slice(0, 100));
          }
        }
      }
    }

    const intentAnalysis = await analyzeIntent(
      effectiveMessage,
      conversationHistory,
      entries,
      lastGeneratedResult
    );

    console.log("Intent Analysis:", intentAnalysis);

    let apiResult = null;
    let responseMessage = "";

    if (
      intentAnalysis.endpoint &&
      intentAnalysis.endpoint !== "none" &&
      intentAnalysis.confidence > 0.5
    ) {
      try {
        apiResult = await routeToAPI(
          intentAnalysis.endpoint,
          intentAnalysis.parameters,
          formData,
          userid,
          effectiveMessage,
          imageUrls
        );

        // üîß Process base64 URLs in API results to prevent Firestore serialization issues
        if (apiResult && apiResult.firebaseOutputUrl && typeof apiResult.firebaseOutputUrl === 'string') {
          if (apiResult.firebaseOutputUrl.startsWith('data:image/')) {
            console.log("üîÑ Converting base64 output URL to Cloudinary URL for Firestore compatibility...");
            try {
              const processedFile = await processBase64Image(apiResult.firebaseOutputUrl, 'design_output.png');
              const cloudinaryUrl = await uploadImageToCloudinary(processedFile);
              apiResult.firebaseOutputUrl = cloudinaryUrl;
              console.log("‚úÖ Converted base64 to Cloudinary URL:", cloudinaryUrl);
            } catch (error) {
              console.error("‚ùå Failed to convert base64 URL:", error);
              // Keep original base64 URL as fallback, but this might still cause Firestore issues
            }
          }
        }
      } catch (error: any) {
        apiResult = {
          status: "error",
          error: error.message,
        };
      }
    }

    // For image operations, return immediately with the result to avoid waiting for Claude
    const imageOperations = ['reframe_image', 'upscale_image', 'analyze_image', 'design', 'design_image', 'elemental_design', 'flow_design'];
    const isImageOperation = imageOperations.includes(intentAnalysis.intent);
    
    if (isImageOperation && apiResult && apiResult.status === 'success') {
      console.log("üöÄ Fast response for image operation - skipping Claude text generation");
      
      // Generate a quick success message based on the operation
      const quickMessages: Record<string, string> = {
        'reframe_image': "Perfect! I've successfully reframed your image üñºÔ∏è The new composition is ready for you to view!",
        'upscale_image': "Great! ‚ú® I've successfully upscaled your image - your enhanced, higher-resolution result is ready!",
        'analyze_image': "I've analyzed your image successfully üîç The analysis is complete and ready for you to view!",
        'design': "Fantastic! üé® I've created your custom design - your beautiful composition is ready!",
        'design_image': "Amazing! üé® I've created your custom design - your new image is ready!",
        'elemental_design': "Fantastic! ‚ö° I've generated your elemental design - check out your new creation!",
        'flow_design': "Perfect! üåä I've created your flow design - your artistic composition is ready!"
      };
      
      const quickMessage = quickMessages[intentAnalysis.intent] || "Your image has been processed successfully!";
      
      const chatResponse: ChatResponse = {
        status: "success",
        message: quickMessage,
        intent: intentAnalysis,
        result: apiResult,
        conversation_id: `${userid}_${Date.now()}`,
      };

      return NextResponse.json(chatResponse);
    }

    responseMessage = await generateResponse(
      effectiveMessage,
      intentAnalysis,
      apiResult
    );

    const chatResponse: ChatResponse = {
      status: "success",
      message: responseMessage,
      intent: intentAnalysis,
      result: apiResult,
      conversation_id: `${userid}_${Date.now()}`,
    };

    return NextResponse.json(chatResponse);
  } catch (error: any) {
    console.error("Intent Route Error:", error);

    const errorResponse: ChatResponse = {
      status: "error",
      message:
        "I encountered an error while processing your request. Please try again.",
      error: error.message || "Unknown error occurred",
    };

    return NextResponse.json(errorResponse, { status: 500 });
  }
}
